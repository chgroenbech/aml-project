\section{Discussion}
\label{sec:discussion}

The variational lower bound for $d = 2$ is comparable to the one for no downsampling after approximately $20$ iterations as seen in Figure~\ref{fig:learning_curves:downsampling_factor}, whereas it is consistently worse for $d = 4$, which makes sense when the dimensions lost follow $d^2$.
Varying the latent size, it is found that a latent size above $10$ does not yield a higher variational lower bound as seen in Figure~\ref{fig:learning_curves:latent_size}, and for $N_{\vec{z}} \geq 30$ the variational lower bound is the same.

Compared to the variational lower bounds with no downsampling, the VAE for $d = 2$ is markedly better than the one for $d = 4$: $\mathcal{L}\idx{test}\order{d = 2} - \mathcal{L}\idx{test}\order{d = 1} \approx \SI{1}{nats}$ compared to $\mathcal{L}\idx{test}\order{d = 4} - \mathcal{L}\idx{test}\order{d = 1} \approx \SI{10}{nats}$.
But the VAE reconstructions in Figure~\ref{fig:samples} for the two downsampling factors are visually comparable for the thicker digits, but less so for the thinner digits. The thin strokes break after Bernoulli sampling. Pixels valuable for positioning similar digits close in latent space are lost and reconstructions confused.  
So the VAE is close to, but not completely robust towards the losses in dimension, when information is sparse. 

Comparing the bicubic interpolation and VAE reconstructions visually, the VAE shows better results for $d = 2$.
While the bicubic interpolation reconstruct the binarised versions, the VAE reconstructions succeed in capturing the original forms.
For $d = 4$, this gives a remarkable difference in favour of the VAE.
The advantage lies in VAE using statistical inference in between all pixels, where bicubic interpolation only considers $16$ neighbouring pixels. This helps the VAE a lot, but could bias reconstructions of unseen symbols, e.g.\ letters, forming approximation to digits instead.
